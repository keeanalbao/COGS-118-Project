{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhlin2024/group_template/blob/main/Proposal_groupXXX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-vK_fOb5Mci"
      },
      "source": [
        "# COGS 118B - Project Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2p6g3jX5Mcm"
      },
      "source": [
        "# Names\n",
        "\n",
        "- Francisco Downey\n",
        "- Keean Albao\n",
        "- Richard Lin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv-AVl0-5Mcm"
      },
      "source": [
        "# Abstract\n",
        "\n",
        "The goal of our project is to segment customers into so that companies, are able to direct marketing to certain customers to retain customers and increase revenue. The data at hand represents state wide customers and the detailed description of their purchase at a particular season. With the data, the project looks to utilize K-means clustering as a means to group customers. By doing so, when a new customer makes a purchase, they can be accurately cateogorized into a group and thus allowing companies to directly market to that customer. Silhouette analysis will be used to ensure accuracy of our clusters. In order to categorize, k-nearest neighbors will be used alongside K-Means."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e5En8Fc5Mcm"
      },
      "source": [
        "# Background\n",
        "\n",
        "Online retailers and e-commerce are becoming increasingly relevant and convenient within recent years. Some of the most popular of these online stores include Amazon, eBay, Kroger, and Etsy. People use online shopping for many of their necessary and impulse purchases, including groceries, household items, clothes, and so on. Even though physical store visits and sales for many product categories are still higher than those of online retailers, the number of online shoppers and e-commerce revenue consistently grows every year<a name=\"radu\"></a>[<sup>[1]</sup>](#radunote).\n",
        "\n",
        "When it comes to online shopping, it is crucial for businesses to understand consumer behavior and shopping habits in order to optimize their marketing strategies. There are many factors that influence consumer behavior. Some of these include personal factors (demographics such as age, gender, and location), psychological factors (consumer responses to marketing messages), and social factors (family dynamics, peer influence, social media presence, and income levels)<a name=\"statista\"></a>[<sup>[2]</sup>](#statistanote)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8BdjgtX5Mcn"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "The problem that we want to solve is what are the different customer similarity groups based on data containing consumer behaviors, demographics, and shopping habits (e.g. age, gender, item purchased, season, location, etc.), and what can businesses do in order to market their products towards these different groups and retain customers?\n",
        "\n",
        "This problem can be quantified by the various features in the data (e.g. age, gender, item purchased, purchase amount), and by using K-Means Clustering in order to assign each data point to a cluster by using distance metrics such as Euclidean distance, and then creating labels for each cluster to differentiate them.\n",
        "\n",
        "This problem can be measured by evaluating clustering performance metrics such as silhouette analysis. Once clusters are formed, we can examine the cluster centroids as well as implement visualization techniques in order to distinguish clusters from one another.\n",
        "\n",
        "This problem can be replicated using the same dataset and techniques since initializing K-Means centroids is done randomly, so there may be some different results for the groups. On the other hand, the problem can be replicated using a completely different dataset containing different features, as well as a different clustering algorithm. This may lead to different results as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgtlxEhk5Mcn"
      },
      "source": [
        "# Data\n",
        "\n",
        "The dataset being used is from the following link<a name=\"zeesolver\"></a>[<sup>[3]</sup>](#zeesolvernote). The dataset has 18 variables and 3900 observations. Each observation has age, gender, item purchased, category of the purchase, purchase amount, location, size of purchase, color of purchase, season in which purchase took place, review rating, subscription status, shipping type, if a discount or promo code was applied, previous purchases, payment method, and frequency of purchases. The critical values are age(integer), gender(Male or Female), category of purchase(string), purchase amount(integer representing dollar amount), location(string of state), size of purchase(S,M,L,XL), season(string of one of four possible seasons), and previous purchases(integer). There will be no cleaning necessary due to the fact that each variable follows the sam format for each observation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3jdHmsB5Mcn"
      },
      "source": [
        "# Proposed Solution\n",
        "\n",
        "We aim to solve this problem using K-Means Clustering. K-Means Clustering will allow us to create clusters that contain customers with similar demographics, behaviors, and spending habits. Then once we have our final clusters, we can use techniques such as centroid examination and visualizations in order to make analyses within each cluster regarding what businesses should do in order to tailor to these different groups.\n",
        "\n",
        "For the K-Means algorithm, we plan to implement Scikit-Learn's KMeans algorithm and fit it to the dataset in order to create our groups. This is an applicable solution since our data is not supervised (we don't have predefined labels for the different groups). The algorithm is also pretty flexible since we can determine the optimal number of clusters that best represent the data. Lastly, K-Means is highly interpretable since the different clusters should clearly represent different groups.\n",
        "\n",
        "When analyzing the clusters, since each cluster centroid represents the mean of all data points within that cluster, we can gain insights into the characteristics of customers in each cluster by analyzing the centroid values for each feature. For example, if one cluster has a high mean purchase amount and a relatively young age, one might label it as “Young High Spenders.” Additionally, we can create plots to visualize the clusters in order to identify patterns/trends that distinguish clusters from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa8Uwx9H5Mco"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "In order to ensure the clustering is accurate, silhouette analysis will be conducted. For each data point the following equation will be followed: The data point's average distance from all data points in its cluster will be subtracted from the data point's average distance from all data points in the neighboring cluster. This value divided by the max of the aforementioned average distances will provide the silhouette coefficient. The desired coefficient will be as close to +1 as possible, representing highly dense clustering."
      ]
    },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "Since the data that we plan on using is public domain, we aren't too worried about data privacy especially since there aren't any names attached to the data points. However, we are fully aware that dealing with personal data (especially finance data) comes with many laws and regulations that are in place in order to maintain personal privacy.\n",
    "\n",
    "However, one crucial privacy/ethical concern that we must take into account is bias in the data. We are aware that the process of data collection and manipulation can lead to unfair or discriminatory outcomes, which is why we need to wholly and accurately represent diverse demographic groups, and regularly evaluate model performance across different clusters."
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrrg_rxj5Mcp"
      },
      "source": [
        "# Project Timeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0893WcXs5Mcp"
      },
      "source": [
        "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
        "|---|---|---|---|\n",
        "| 2/19 | 11 AM | Brainstorm topics/questions | Discuss/decide on final project topic; work on proposal |\n",
        "| 2/22 | 12 PM | Edit, finalize, and submit proposal | Discuss next steps of project; assign responsibilities |\n",
        "| 2/29 | 12 PM | Import/wrangle data; perform EDA | Review/edit wrangling/EDA; discuss analysis; assign responsibilities |\n",
        "| 3/7  | 12 PM | Complete analysis | Discuss results; assign responsibilities |\n",
        "| 3/14 | 12 PM | Draft results/conclusion/discussion | Discuss/edit full project |\n",
        "| 3/17 | Before 11:59 PM | NA | Turn in Final Project |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCzVpJSo5Mcp"
      },
      "source": [
        "# Footnotes\n",
        "\n",
        "<a name=\"radunote\"></a>1.[^](#radu): Radu, V. (2 Feb 2024) Consumer Behavior in Marketing. Patterns, Types & Segmentation. *Omniconvert*. https://www.omniconvert.com/blog/consumer-behavior-in-marketing-patterns-types-segmentation/<br>\n",
        "<a name=\"statistanote\"></a>2.[^](#statista): Statista. Shopping Behavior. *Statista*. https://www.statista.com/markets/423/topic/536/shopping-behavior/#overview<br>\n",
        "<a name=\"zeesolvernote\"></a>3.[^](#zeesolver): Solver, Z. (Nov 2023) Consumer Behavior and Shopping Habits Dataset. *Kaggle*. https://www.kaggle.com/datasets/zeesolver/consumer-behavior-and-shopping-habits-dataset/data<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meGqdRvi5Mcp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
